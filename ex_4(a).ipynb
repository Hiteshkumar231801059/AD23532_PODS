{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcWnJslQvffAOls8wNEg/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiteshkumar231801059/AD23532_PODS/blob/main/ex_4(a).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9R0L2C9npW2r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90XyDGK0pe06",
        "outputId": "1f29692b-22eb-43b5-e495-013a476933aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Reviews.csv\")\n",
        "reviews = df[['Text']]\n",
        "reviews.dropna(inplace=True)\n",
        "reviews = reviews[:10000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_f__ek3piNS",
        "outputId": "30c8ea30-8a19-45c5-d0b1-3f73578f04b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-197819376.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  reviews.dropna(inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "s6cHPXH_qjcX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)"
      ],
      "metadata": {
        "id": "lAtceHLjqjie"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['Cleaned_Text'] = reviews['Text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "viksqL1_qj91"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(reviews['Cleaned_Text'])"
      ],
      "metadata": {
        "id": "6JihNR79qj_R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_reviews(query, k=5):\n",
        "    cleaned_query = preprocess(query)\n",
        "    query_vec = vectorizer.transform([cleaned_query])\n",
        "    similarity = cosine_similarity(query_vec, tfidf_matrix)\n",
        "    top_k_indices = similarity[0].argsort()[-k:][::-1]\n",
        "    results = reviews.iloc[top_k_indices][['Text', 'Cleaned_Text']]\n",
        "    return results"
      ],
      "metadata": {
        "id": "65K1dQDsr5da"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Great product\")\n",
        "print(search_reviews(\"great product\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0oaMApHr5gu",
        "outputId": "3b7851e0-d98c-4046-c9fd-3ac4a19717b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great product\n",
            "                                                   Text  \\\n",
            "8952  This is a good product with great price.  I re...   \n",
            "5617  I have ordered this product twice now and the ...   \n",
            "2557  I have very little to say about the product ex...   \n",
            "4471  This is a great product. Great flavors and ver...   \n",
            "3681  It is great! I like it alot. Great price too. ...   \n",
            "\n",
            "                                           Cleaned_Text  \n",
            "8952  good product great price received treat please...  \n",
            "5617  ordered product twice service product great wo...  \n",
            "2557  little say product except great product delive...  \n",
            "4471  great product great flavors fresh received qui...  \n",
            "3681  great like alot great price think delicious to...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Query: disappointed\")\n",
        "print(search_reviews(\"worst\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKJoJKaGr5j7",
        "outputId": "7e5e956b-b46e-4ad5-ff0c-c90cd22f5af0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: disappointed\n",
            "                                                   Text  \\\n",
            "4592  This was the worst tasting tea, actually the w...   \n",
            "5974  I am big coffee lover.  This was some of the w...   \n",
            "9381  The worst!!! it is just plan awful bitter and ...   \n",
            "8672  The worst!!! it is just plan awful bitter and ...   \n",
            "4863  this gum is the worst i have ever purchased, p...   \n",
            "\n",
            "                                           Cleaned_Text  \n",
            "4592  worst tasting tea actually worst tasting anyth...  \n",
            "5974  big coffee lover worst coffee ever smells wond...  \n",
            "9381  worst plan awful bitter strong taste hazel nut...  \n",
            "8672  worst plan awful bitter strong taste hazel nut...  \n",
            "4863  gum worst ever purchased plain simple within t...  \n"
          ]
        }
      ]
    }
  ]
}